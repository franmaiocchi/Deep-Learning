{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning\n",
    "\n",
    "# Keras Guide\n",
    "#### Francisco Maiocchi\n",
    "\n",
    "***\n",
    "### Introducción\n",
    "Keras es la API de alto nivel para crear y entrenar modelos de deep learning. Es usado para prototipado rápido, investigación avanzada, producción y cuenta con tres ventajas claves:  \n",
    "\n",
    "+ __User friendly:__ Keras es simple y está optimizado para los usos más comunes. Brinda información clara y entendible sobre los errores.  \n",
    "+ __Modular:__ los modelo de Keras se construyen conectando distintos bloques.\n",
    "+ __Facil de escalar:__ se pueden crear nuevos bloques, capas, loss functions para probar ideas e investigar. \n",
    "\n",
    "Este guía está basada en la que se encuentra en la web oficial de TensorFlow en https://www.tensorflow.org/guide/keras?hl=es\n",
    "\n",
    "***\n",
    "### Imports\n",
    "tf.keras es la implementación de TensorFlow de la Keras API specification. Es una API de alto nivel para construir y entrenar modelos que incluye soporte para funciones especificas de TensorFlow, como eager execution, tf.data pipelines y estimadores. tf.keras hace que TensorFlow sea mucho más facil de usar sin sacrificar flexibilidad ni performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "# Importo TensorFlow como tf\n",
    "import tensorflow as tf\n",
    "# Importo keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# Librerias auxiliares\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras puede correr cualquier código compatible con Keras pero hay que tener en cuenta que:  \n",
    "+ La versión de tf.keras del último TensorFlow puede no ser la misma que la versión de PyPI. Checkear tf.keras.version.  \n",
    "+ Cuando se guardan los pesos de un modelo, por defecto tf.keras lo hace en su formato checkpoint. Si se quiere usar HDF5 se debe pasar save_format = 'h5' a la función. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Construcción de un modelo simple\n",
    "\n",
    "#### Modelo secuencial\n",
    "En keras, para construir un modelo se deben encadenar capas o layers. Generalmente, un modelo es un grafo de capas. El tipo de modelo más comun es una pila de capas que se contruye mediante el modelo tf.keras.Sequential.  \n",
    "\n",
    "Para construir una simple red fully-connected (perceptron multi capa): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Agrega una capa densamente conectada o fully-connected de 64 neuronas con activación \n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Se agrega otra capa\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Se agrega una capa con activación softmax de 10 neuronas\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurando el modelo\n",
    "Existen un monton de capas disponibles en tf.keras.layers. La mayoría comparten estos parametros:  \n",
    "\n",
    "+ __activation__: función activación de la capa. Este parametro se especifica con el nombre de una función ya implementada o como un callable object. Por defecto, ninguna activación es aplicada.  \n",
    "+ __kernel_initializer__ y __bias_initializer__: el esquema de inicialización que crea los pesos de la capa. Este parametro es un nombre o un callable object. Por defecto se utiliza el inicializador __\"Glorot uniform\"__. \n",
    "+ __kernel_regularizer__ y __bias_regularizer__: el esquema de regularización que se aplica a los pesos de la capa, como por ejemplo L1 y L2 regularization. Estas técnicas se utilizan para prevenir el overfitting o sobreentrenamiento. Por defecto, no se utiliza ninguna regularización.  \n",
    "\n",
    "Como ejemplo, vamos a instanciar una tf.keras.layers.Dense y ver sus argumentos de construcción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x2197b7c2e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crea una capa sigmoid\n",
    "keras.layers.Dense(64, activation='sigmoid')\n",
    "# O:\n",
    "keras.layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# Una capa lineal con L1 regularization de factor 0.01 aplicado al kernel\n",
    "keras.layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# Una capa lineal con L2 regularization de factor 0.01 aplicado al bias del vector\n",
    "keras.layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# Una capa lineal con el kernel inicializado a una matriz aleatoria ortogonal\n",
    "keras.layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# Una capa lineal con un bias de 2.0\n",
    "keras.layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capa Dense implementa la operación: $output = activation(dot(input, kernel) + bias)$ donde activation es la función activación, kernel es la matriz de pesos de la capa y bias es el offset o bias del vector creado por la capa.  \n",
    "\n",
    "Los argumentos posibles son:  \n",
    "\n",
    "+ __units__: Cantidad de neuronas o dimensionalidad del espacio de salida.\n",
    "+ __activation__: Funcion activación a usar. Si no se especifica, no se utiliza ninguna.\n",
    "+ __use_bias__: Boolean. Si se utiliza o no un bias vector.\n",
    "+ __kernel_initializer__: Inicializador de los pesos del kernel.\n",
    "+ __bias_initializer__: Inicializador del vector de bias.\n",
    "+ __kernel_regularizer__: Función regularización que se aplica al kernel. \n",
    "+ __bias_regularizer__: Función regularización que se aplica al vector de bias.\n",
    "+ __activity_regularizer__: Función regularización que se aplica a la función activación.\n",
    "+ __kernel_constraint__: Restricción que se aplica a los pesos.\n",
    "+ __bias_constraint__: Restricción que se aplica al bias.  \n",
    "\n",
    "***\n",
    "### Entrenamiento y evaluación\n",
    "#### Configuración de entrenamiento\n",
    "\n",
    "Luego de que el modelo es contruido, se debe configurar el proceso de aprendizaje llamando al método compile:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Agrego una capa fully-connected de 64 unidades\n",
    "keras.layers.Dense(64, activation='relu'),\n",
    "# Agrego otra igual\n",
    "keras.layers.Dense(64, activation='relu'),\n",
    "# Agrego una capa con activación softmax de 10 neuronas\n",
    "keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.compile toma tres argumentos muy importantes: \n",
    "+ __optimizer__: Este objeto especifica el proceso de entrenamiento. https://www.tensorflow.org/api_docs/python/tf/train?hl=es\n",
    "+ __loss__: La función a minimizar durante la optimización. https://www.tensorflow.org/api_docs/python/tf/keras/losses?hl=es\n",
    "+ __metrics__: Métrica que se utiliza para monitorear el entrenamiento. https://www.tensorflow.org/api_docs/python/tf/keras/metrics?hl=es  \n",
    "\n",
    "Adelante tenemos algunos ejemplos de configuración de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para regresión con error cuadrático medio \n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configuración para clasificación en categorías\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos de entrada tipo NumPy\n",
    "Para pequeños datasets, se usa NumPy arrays para entrenar y evaluar los modelos. El modelo es entrenado por los datos de entrenamiento con el método fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 327us/step - loss: 11.6054 - categorical_accuracy: 0.1020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 11.5629 - categorical_accuracy: 0.1150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 11.5477 - categorical_accuracy: 0.1120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 11.5445 - categorical_accuracy: 0.1100\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 11.5436 - categorical_accuracy: 0.1170\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 11.5413 - categorical_accuracy: 0.1070\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 11.5404 - categorical_accuracy: 0.1160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 11.5398 - categorical_accuracy: 0.1100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 11.5408 - categorical_accuracy: 0.1200\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 11.5393 - categorical_accuracy: 0.1170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2197b7c2860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.fit toma tres importantes argumentos:  \n",
    "+ __epochs__: Una época es una iteración a lo largo de todo el set de entrenamiento (aunque se hace en lotes más pequeños).\n",
    "+ __batch_size__: Cuando se le ingresa con NumPy data, el modelo divide los datos en lotes más pequeños (batchs) e itera sobre estos lotes durante el entrenamiento. Este número especifica el tamaño del lote. Hay que tener en cuenta que si el total de datos de entrada no es divisible por tamaño del lote, el último lote será más pequeño.\n",
    "+ __validation_data__: cuando se evalua un modelo, se necesita monitorear su performance facilmente con datos de validación. Si se le pasa una tupla de entradas y otra de salidas esperadas o labels, el modelo puede mostrar la loss function y las métricas para los datos de validación al final de cada época. Es importante aclarar que estos datos no son usados para entrenar, es decir, no afectan a los pesos del kernel ni al bias.  \n",
    "\n",
    "Aca tenemos un ejemplo utilizando datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 133us/step - loss: 11.4898 - categorical_accuracy: 0.1190 - val_loss: 11.6175 - val_categorical_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.4868 - categorical_accuracy: 0.1190 - val_loss: 11.6115 - val_categorical_accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 11.4867 - categorical_accuracy: 0.0950 - val_loss: 11.6097 - val_categorical_accuracy: 0.1200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 11.4853 - categorical_accuracy: 0.1280 - val_loss: 11.6269 - val_categorical_accuracy: 0.1100\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 11.4852 - categorical_accuracy: 0.1110 - val_loss: 11.6119 - val_categorical_accuracy: 0.1400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 11.4824 - categorical_accuracy: 0.1220 - val_loss: 11.6120 - val_categorical_accuracy: 0.1200\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 11.4823 - categorical_accuracy: 0.1150 - val_loss: 11.6146 - val_categorical_accuracy: 0.0700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.4790 - categorical_accuracy: 0.1260 - val_loss: 11.6236 - val_categorical_accuracy: 0.1200\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 11.4780 - categorical_accuracy: 0.1440 - val_loss: 11.6245 - val_categorical_accuracy: 0.1300\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.4750 - categorical_accuracy: 0.1260 - val_loss: 11.6261 - val_categorical_accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2197bd596d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar datasets de tf.data\n",
    "Para grandes datasets o entrenamiento en multiples dispositivos se utiliza la API Datasets. Se pasa un tf.data.Dataset al método fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4581 - categorical_accuracy: 0.1333\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 898us/step - loss: 11.5143 - categorical_accuracy: 0.1479\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 898us/step - loss: 11.4787 - categorical_accuracy: 0.1479\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4774 - categorical_accuracy: 0.1604\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4685 - categorical_accuracy: 0.1760\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4817 - categorical_accuracy: 0.1677\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 931us/step - loss: 11.4662 - categorical_accuracy: 0.1813\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 997us/step - loss: 11.4698 - categorical_accuracy: 0.1813\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 997us/step - loss: 11.4533 - categorical_accuracy: 0.1771\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 898us/step - loss: 11.4708 - categorical_accuracy: 0.1677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2197bd615c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancias de un dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# No olvidat de especificar steps_per_epoch cuando se llama fit en un dataset\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá, el método fit utiliza el argumento steps_per_epoch. Esto se refiere la cantidad de pasos de entrenamiento que el modelo corre antes de pasar a la siguiente época. COmo el Dataset ya viene en lotes de datos, no hace falta especificar el batch_size.  \n",
    "Los datasets también se puede utilizar para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 11.4155 - categorical_accuracy: 0.1521 - val_loss: 11.7025 - val_categorical_accuracy: 0.1042\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 964us/step - loss: 11.4740 - categorical_accuracy: 0.1656 - val_loss: 11.2636 - val_categorical_accuracy: 0.0938\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4384 - categorical_accuracy: 0.1521 - val_loss: 11.3373 - val_categorical_accuracy: 0.0417\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4422 - categorical_accuracy: 0.1552 - val_loss: 11.5487 - val_categorical_accuracy: 0.0521\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4300 - categorical_accuracy: 0.1708 - val_loss: 11.6889 - val_categorical_accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4443 - categorical_accuracy: 0.1927 - val_loss: 11.2523 - val_categorical_accuracy: 0.0521\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4323 - categorical_accuracy: 0.1896 - val_loss: 11.3238 - val_categorical_accuracy: 0.0729\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4330 - categorical_accuracy: 0.1885 - val_loss: 11.5512 - val_categorical_accuracy: 0.0417\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4203 - categorical_accuracy: 0.1604 - val_loss: 11.7426 - val_categorical_accuracy: 0.1042\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4394 - categorical_accuracy: 0.1813 - val_loss: 11.2743 - val_categorical_accuracy: 0.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2197bd7ffd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación y predicción\n",
    "Los métodos tf.keras.Model.evaluate y tf.keras.Model.predict pueden usar NumPy data y tf.data.Dataset.  \n",
    "\n",
    "Para evaluar el modo de inferencia de la loss function y de la métrica de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 73us/step\n",
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.394348398844402, 0.18854166666666666]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y para predecir la salida de la última capa según los datos de entrada (como NumPy array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Construcción de modelo avanzados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
