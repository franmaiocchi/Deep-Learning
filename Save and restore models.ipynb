{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning\n",
    "\n",
    "# Overfitting and underfitting\n",
    "#### Francisco Maiocchi\n",
    "\n",
    "***\n",
    "### Introducción\n",
    "\n",
    "El progreso de los modelos se puede guardar durante y luego del entrenamiento. Esto quiere decir que un modelo puede volver a entrenarse desde donde había frenado sin necesidad de arrancar de nuevo. Esto también permite compartir el modelo para que otras personas puedan recrear el trabajo. Cuando se publican modelos y técnicas en investigación, la mayoría comparte:  \n",
    "\n",
    "+ El código para crear el modelo.\n",
    "+ Los pesos o parámetros del modelo.\n",
    "\n",
    "Compartir esto permite al resto entender como funciona el modelo y les permite probarlos con datos nuevos.\n",
    "\n",
    "Utiliza KERAS que es la API de alto nivel de TensorFlow. Este ejemplo está en web oficial de TensorFlow en https://www.tensorflow.org/tutorials/keras/save_and_restore_models?hl=es  \n",
    "\n",
    "Por otro lado, hay muchas formas de guardar modelos de TensorFlow, dependiendo de la API que se utilice.\n",
    "\n",
    "***\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Importo TensorFlow como tf\n",
    "import tensorflow as tf\n",
    "# Importo keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# Librerias auxiliares\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Obtención del dataset\n",
    "Vamos a usar el dataset de MNIST para entrenar el modelo y guardar los pesos. Para acelerar esta demostración, solo vamos a usar los primeros 1000 ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Definimos el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Returns a short sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "  \n",
    "    model.compile(optimizer='adam', \n",
    "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Guardar checkpoints durante el entrenamiento\n",
    "El uso más común es para guardar checkpoints durante y al final del entrenamiento. De esta forma podemos usar un modelo ya entrenado sin la necesidad de volver a entrenarlo o retomar un entrenamiento donde lo habíamos dejado en caso de que lo hayamos interrumpido.  \n",
    "\n",
    "tf.keras.callbacks.ModelCheckpoint es un callback que realiza esta tarea. La tarea recibe un par de argumentos de entrada para configurar el checkpoint.  \n",
    "\n",
    "#### Uso del checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 1.2725 - acc: 0.6507\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1974 - acc: 0.6680 - val_loss: 0.7414 - val_acc: 0.7770\n",
      "Epoch 2/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 0.4269 - acc: 0.8772- ETA: 0s - loss: 0.4356 - acc: 0.\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 643us/step - loss: 0.4302 - acc: 0.8770 - val_loss: 0.5652 - val_acc: 0.8190\n",
      "Epoch 3/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.2963 - acc: 0.9260\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.2914 - acc: 0.9280 - val_loss: 0.4761 - val_acc: 0.8550\n",
      "Epoch 4/10\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.1988 - acc: 0.9594\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.1970 - acc: 0.9600 - val_loss: 0.4357 - val_acc: 0.8550\n",
      "Epoch 5/10\n",
      " 864/1000 [========================>.....] - ETA: 0s - loss: 0.1505 - acc: 0.9699\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.1492 - acc: 0.9690 - val_loss: 0.4183 - val_acc: 0.8620\n",
      "Epoch 6/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 0.1142 - acc: 0.9784\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.1157 - acc: 0.9790 - val_loss: 0.4361 - val_acc: 0.8600\n",
      "Epoch 7/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0922 - acc: 0.9833\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0922 - acc: 0.9830 - val_loss: 0.4119 - val_acc: 0.8610\n",
      "Epoch 8/10\n",
      " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0656 - acc: 0.9914\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0657 - acc: 0.9910 - val_loss: 0.4024 - val_acc: 0.8710\n",
      "Epoch 9/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0506 - acc: 0.9967\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 0.0497 - acc: 0.9970 - val_loss: 0.4042 - val_acc: 0.8690\n",
      "Epoch 10/10\n",
      " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0371 - acc: 0.9989\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F372320>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 0s 458us/step - loss: 0.0384 - acc: 0.9990 - val_loss: 0.4214 - val_acc: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2684eb7c518>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = 10, \n",
    "          validation_data = (test_images,test_labels),\n",
    "          callbacks = [cp_callback])  # pass callback to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad C es OS\n",
      " El n£mero de serie del volumen es: EC0A-1A5D\n",
      "\n",
      " Directorio de C:\\Users\\Francisco\\Desktop\\PDS IIA\\Deep-Learning\\training_1\n",
      "\n",
      "20/12/2018  17:14    <DIR>          .\n",
      "20/12/2018  17:14    <DIR>          ..\n",
      "20/12/2018  17:14                71 checkpoint\n",
      "20/12/2018  17:14         1.631.508 cp.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:14               647 cp.ckpt.index\n",
      "               3 archivos      1.632.226 bytes\n",
      "               2 dirs  101.139.369.984 bytes libres\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear un nuevo modelo sin entrenar. Para cargar un modelo con pesos guardados, se necesita tener un modelo con exactamente la misma arquitectura que el modelo original. Como es exactamente igual, puede compartir los pesos a pesar de ser una instancia diferente.  \n",
    "\n",
    "Ahora vamos a reconstruir un nuevo modelo y evaluarlo con el set de test (sin entrenarlo previamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 302us/step\n",
      "Untrained model, accuracy:  8.50%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos los pesos del checkpoint..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 90us/step\n",
      "Restored model, accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opciones de checkpoint callback\n",
    "El callback ofrece distintas opciones para dar distintos nombres a los checkpoints y ajustar la frecuencia.  \n",
    "\n",
    "Vamos a entrenar un nuevo modelo y guardar checkpoints con nombres únicos cada 5 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x00000268504AB160>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2684eb7c5c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include the epoch in the file name. (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # Save weights, every 5-epochs.\n",
    "    period=5)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs = 50, callbacks = [cp_callback],\n",
    "          validation_data = (test_images,test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad C es OS\n",
      " El n£mero de serie del volumen es: EC0A-1A5D\n",
      "\n",
      " Directorio de C:\\Users\\Francisco\\Desktop\\PDS IIA\\Deep-Learning\\training_2\n",
      "\n",
      "20/12/2018  17:23    <DIR>          .\n",
      "20/12/2018  17:23    <DIR>          ..\n",
      "20/12/2018  17:23                81 checkpoint\n",
      "20/12/2018  17:22         1.631.508 cp-0005.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:22               647 cp-0005.ckpt.index\n",
      "20/12/2018  17:22         1.631.508 cp-0010.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:22               647 cp-0010.ckpt.index\n",
      "20/12/2018  17:22         1.631.508 cp-0015.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:22               647 cp-0015.ckpt.index\n",
      "20/12/2018  17:22         1.631.508 cp-0020.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:22               647 cp-0020.ckpt.index\n",
      "20/12/2018  17:22         1.631.508 cp-0025.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:22               647 cp-0025.ckpt.index\n",
      "20/12/2018  17:22         1.631.508 cp-0030.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:22               647 cp-0030.ckpt.index\n",
      "20/12/2018  17:22         1.631.508 cp-0035.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:22               647 cp-0035.ckpt.index\n",
      "20/12/2018  17:23         1.631.508 cp-0040.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:23               647 cp-0040.ckpt.index\n",
      "20/12/2018  17:23         1.631.508 cp-0045.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:23               647 cp-0045.ckpt.index\n",
      "20/12/2018  17:23         1.631.508 cp-0050.ckpt.data-00000-of-00001\n",
      "20/12/2018  17:23               647 cp-0050.ckpt.index\n",
      "              21 archivos     16.321.631 bytes\n",
      "               2 dirs  101.120.978.944 bytes libres\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0050.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testear vamos a resetear el modelo y cargarlo con el último checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 224us/step\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Que son estos archivos?\n",
    "Los códigos de arriba guardan los pesos en una colección de archivos con formato checkpoint que contienen solo los pesos en formato binario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Guardar los pesos manualmente\n",
    "Arriba vimos como cargar los pesos en un modelo.  \n",
    "\n",
    "Guardar los pesos manualmente es igual de simple, solo se debe usar Model.save_weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000002684F7C43C8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1000/1000 [==============================] - 0s 232us/step\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Restore the weights\n",
    "model = create_model()\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Guardar el modelo entero\n",
    "Se puede guardar el modelo entero en un archivo que contiene los pesos, la configuración del modelo y hasta la configurazion del optimizer. Esto permite guardar un checkpoint y continuar el entrenamiento más adelante.  \n",
    "\n",
    "Guardar un modelo completamente funcional es muy útil. Se puede cargar en TensorFlow.js (HDF5, saved model) y luego entrenarlo y correrlo en un navegador o convertirlo en una aplicación movil con TensorFlow Lite (HDF5, Saved Model).\n",
    "\n",
    "#### Como un archivo HDF5\n",
    "Keras provee un formato de archivo básico para guardar llamado HDF5. Para nuestro propósito se puede considerar un archivo binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1355 - acc: 0.6780\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 409us/step - loss: 0.4173 - acc: 0.8840\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 386us/step - loss: 0.2812 - acc: 0.9140\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 396us/step - loss: 0.2025 - acc: 0.9520 0s - loss: 0.2064 - acc: 0.953\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 0.1550 - acc: 0.9640\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "# You need to use a keras.optimizer to restore the optimizer state from an HDF5 file.\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora recreamos el modelo desde ese archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including weights and optimizer.\n",
    "new_model = keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkeamos su efectividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 264us/step\n",
      "Restored model, accuracy: 85.20%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta técnica guarda todo:  \n",
    "\n",
    "+ Los pesos.\n",
    "+ La configuración del modelo (arquitectura).\n",
    "+ La configuración del optimizer.\n",
    "\n",
    "Keras guarda los modelo inspeccionando la arquitectura. Actualmente no es capaz de guardar los optimizers desde tf.train. Cuando se usa uno de estos es necesario recompilar el modelo luego de cargarlo y se pierde el estado del optimizer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
